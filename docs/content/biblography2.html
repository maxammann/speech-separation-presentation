<section>
    <div class="references" role="doc-bibliography">
        <div id="ref-Wang2006">
            <p>[23] D. L. Wang and G. J. Brown, <em>Computational auditory scene analysis: Principles, algorithms, and
                applications</em>. Wiley, 2006.</p>
        </div>
        <div id="ref-Festen1990">
            <p>[24] J. M. Festen and R. Plomp, “Effects of fluctuating noise and interfering speech on the
                speech-reception threshold for impaired and normal hearing,” <em>The Journal of the Acoustical Society
                    of America</em>, vol. 88, no. 4, pp. 1725–1736, Oct. 1990.</p>
        </div>
        <div id="ref-Lee1999">
            <p>[25] D. D. Lee and H. S. Seung, “Learning the parts of objects by non-negative matrix factorization,”
                <em>Nature</em>, vol. 401, no. 6755, pp. 788–791, Oct. 1999.</p>
        </div>
        <div id="ref-Dubnov2002">
            <p>[26] S. Dubnov, “Extracting sound objects by independent subspace analysis.” Jun-2002.</p>
        </div>
        <div id="ref-Casey2000">
            <p>[27] M. A. Casey and A. Westner, “Separation of mixed audio sources by independent subspace analysis,” in
                <em>ICMC</em>, 2000.</p>
        </div>
        <div id="ref-Wang2005">
            <p>[28] D. Wang, “On Ideal Binary Mask As the Computational Goal of Auditory Scene Analysis,” in <em>Speech
                separation by humans and machines</em>, P. Divenyi, Ed. Springer, 2005, pp. 181–197.</p>
        </div>
        <div id="ref-Schuller2010">
            <p>[29] B. Schuller, F. Weninger, M. Wollmer, Y. Sun, and G. Rigoll, “Non-negative matrix factorization as
                noise-robust feature extractor for speech recognition,” in <em>IEEE international conferenceon
                    acoustics, speech and signal processing (icassp)</em>, 2010.</p>
        </div>
        <div id="ref-Qian2018">
            <p>[30] Y.-m. Qian, C. Weng, X.-k. Chang, S. Wang, and D. Yu, “Past review, current progress, and challenges
                ahead on the cocktail party problem,” <em>Frontiers of Information Technology &amp; Electronic
                    Engineering</em>, vol. 19, no. 1, pp. 40–63, Jan. 2018.</p>
        </div>
        <div id="ref-Hu2007">
            <p>[31] Y. Hu and P. C. Loizou, “Subjective comparison and evaluation of speech enhancement algorithms,”
                <em>Speech Communication</em>, vol. 49, nos. 7-8, pp. 588–601, Jul. 2007.</p>
        </div>
        <div id="ref-Ephraim1985">
            <p>[32] Y. Ephraim and D. Malah, “Speech enhancement using a minimum mean-square error log-spectral
                amplitude estimator,” <em>IEEE Transactions on Acoustics, Speech, and Signal Processing</em>, vol. 33,
                no. 2, pp. 443–445, Apr. 1985.</p>
        </div>
        <div id="ref-Marr1982">
            <p>[33] D. Marr, <em>Vision: A computational investigation into the human representation and processing of
                visual information</em>. Henry Holt; Co., Inc., 1982.</p>
        </div>
    </div>
</section>
